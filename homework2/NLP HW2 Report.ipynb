{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 of NLP for DeepLearning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A10515001 李大祥  \n",
    "> 2018-04-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、使用原神经网络和属性\n",
    "\n",
    "第一步是先用原来投影片的神经网络结构和表格的属性来预测。开始的时候自己乱调了几个参数，结果成绩才　0.61812　而已。后来下面是按计划调整测试。\n",
    "\n",
    "### 调整　batch_size　参数\n",
    "这里是修改 validation_split 的参数值，表示按一定比例从训练集中取出一部分作为验证集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用原参数成绩：　0.70226\n",
    "epochs = 100, validation_split = 0.2, batch_size = 10, verbose = 1\n",
    "batch_size=10, verbose=0\n",
    "\n",
    "# 成绩：　0.69902\n",
    "epochs = 100, validation_split = 0.5, batch_size = 10, verbose = 1\n",
    "batch_size=10, verbose=0\n",
    "\n",
    "# 成绩：　0.71521\n",
    "epochs = 100, validation_split = 0.35, batch_size = 10, verbose = 1\n",
    "batch_size=10, verbose=0\n",
    "0.71521\n",
    "\n",
    "# 成绩：　0.72491\n",
    "epochs = 100, validation_split = 0.275, batch_size = 10, verbose = 1\n",
    "batch_size=10, verbose=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调整　batch_size　参数\n",
    "\n",
    "batch_size 是每次训练的样本个数，过多或过少都会影响准确率，当然也要和其他参数配合，5 个是比较合适的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 成绩：　0.73139\n",
    "epochs = 100, validation_split = 0.275, batch_size = 5, verbose = 1\n",
    "batch_size=5, verbose=0\n",
    "\n",
    "# 成绩：　0.68284\n",
    "epochs = 100, validation_split = 0.275, batch_size = 4, verbose = 1\n",
    "batch_size=4, verbose=0\n",
    "\n",
    "\n",
    "# 成绩：　0.68932\n",
    "epochs = 100, validation_split = 0.275, batch_size = 2, verbose = 1\n",
    "batch_size=2, verbose=0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调整　if value[0] > 0.4　参数\n",
    "\n",
    "调整分类的标准线，事实证明大概在0.5 左右是比较合适的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.72815\n",
    "epochs = 500, validation_split = 0.05, batch_size = 2, verbose = 1\n",
    "batch_size=2, verbose=0\n",
    "if value[0] > 0.7:\n",
    "    \n",
    "\n",
    "# 0.67637\n",
    "epochs = 500, validation_split = 0.05, batch_size = 2, verbose = 1\n",
    "batch_size=2, verbose=0\n",
    "if value[0] > 0.4:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上使用原始的属性训练，Kaggle 成绩最好达到 0.73786 ,之后怎么调整都没用了。\n",
    "\n",
    "\n",
    "## 二、增加了boat训练属性\n",
    "\n",
    "大概和之前隔了很久，和其他做的准确率更高的同学请教了一下，发现加入 boat 属性会让结果准确率会变好，所以以下都是在加入 boat 属性的前提下进行调整参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.91909\n",
    "model.fit(x = train_result, y = train_label, epochs = 200, validation_split = 0.275, batch_size = 5, verbose = 1)\n",
    "scores = model.evaluate(x = train_result, y = train_label, batch_size=5)\n",
    "res = model.predict(test_feature, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调整 validation_split\n",
    "第二次调小了 validation_split ，因为我认为大概如果这个数值过大那么会出现过拟合的问题，和 train 相关性会变大。所以调小一些，果然结果变好,但是过小也不行、不稳定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.93527\n",
    "model.fit(x = train_result, y = train_label, epochs = 200, validation_split = 0.175, batch_size = 5, verbose = 1)\n",
    "scores = model.evaluate(x = train_result, y = train_label, batch_size=5)\n",
    "res = model.predict(test_feature, batch_size=5, verbose=0)\n",
    "\n",
    "# 0.92233\n",
    "model.fit(x = train_result, y = train_label, epochs = 200, validation_split = 0.1, batch_size = 5, verbose = 1)\n",
    "scores = model.evaluate(x = train_result, y = train_label, batch_size=5)\n",
    "res = model.predict(test_feature, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调整训练次数\n",
    "结果发现5000次的效果不一定比500次的好很多。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.94822\n",
    "model.fit(x = train_result, y = train_label, epochs = 500, validation_split = 0.1, batch_size = 5, verbose = 1)\n",
    "scores = model.evaluate(x = train_result, y = train_label, batch_size=5)\n",
    "res = model.predict(test_feature, batch_size=5, verbose=0)\n",
    "\n",
    "# 0.94174\n",
    "model.fit(x = train_result, y = train_label, epochs = 5000, validation_split = 0.1, batch_size = 5, verbose = 1)\n",
    "scores = model.evaluate(x = train_result, y = train_label, batch_size=5)\n",
    "res = model.predict(test_feature, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调整 batch_size 和 validation_split\n",
    "减少这两个，猜测能降低过拟合的可能性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.93203\n",
    "model.fit(x = train_result, y = train_label, epochs = 500, validation_split = 0.07, batch_size = 2, verbose = 1)\n",
    "scores = model.evaluate(x = train_result, y = train_label, batch_size=2)\n",
    "res = model.predict(test_feature, batch_size=2, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多加一层神经元看看\n",
    "接下来调整神经网络,并保持这些参数不变。\n",
    "```\n",
    "model.fit(x = train_result, y = train_label, epochs = 500, validation_split = 0.07, batch_size = 5, verbose = 1)\n",
    "scores = model.evaluate(x = train_result, y = train_label, batch_size=5)\n",
    "res = model.predict(test_feature, batch_size=5, verbose=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.89644\n",
    "model.add(Dense(units=100, input_dim=10, kernel_initializer='uniform'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(units=60, kernel_initializer='uniform'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(units=30, kernel_initializer='uniform'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 0.92556\n",
    "model.add(Dense(units=100, input_dim=10, kernel_initializer='uniform'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(units=50, kernel_initializer='uniform'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(units=25, kernel_initializer='uniform'))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总共尝试了57次，我找到的最好的代码参数是上交的代码那样子配置，Kaggle 成绩是 0.94822　。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
