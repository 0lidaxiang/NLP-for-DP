{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['some', 'thing', 'to', 'eat', 'some', 'thing', 'to']\n",
      "[2, 3, 3, 9, 2, 3, 3]\n",
      "[2, 3, 3, 4]\n",
      "OrderedDict([('some', 3), ('thing', 3), ('to', 3), ('eat', 1), ('drink', 1)])\n",
      "{'eat': 4, 'to': 3, 'thing': 2, 'drink': 5, 'some': 1}\n",
      "{'eat': 1, 'to': 2, 'thing': 2, 'drink': 1, 'some': 2}\n",
      "{1: 2, 2: 2, 3: 2, 4: 1, 5: 1}\n",
      "\n",
      "\n",
      "\n",
      "[1, 2, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "import keras.preprocessing.text as T\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "text1='some thing to eat some thing to '\n",
    "text2='some thing to drink'\n",
    "texts=[text1,text2]\n",
    "\n",
    "print (T.text_to_word_sequence(text1))  #以空格区分，中文也不例外 ['some', 'thing', 'to', 'eat']\n",
    "print (T.one_hot(text1,10))  #[7, 9, 3, 4] -- （10表示数字化向量为10以内的数字）\n",
    "print ( T.one_hot(text2,10))  #[7, 9, 3, 1]\n",
    "\n",
    "tokenizer = Tokenizer(num_words=3) #num_words:None或整数,处理的最大单词数量。少于此数的单词丢掉\n",
    "tokenizer.fit_on_texts(texts)\n",
    "print( tokenizer.word_counts) #[('some', 2), ('thing', 2), ('to', 2), ('eat', 1), ('drink', 1)]\n",
    "print( tokenizer.word_index) #{'some': 1, 'thing': 2,'to': 3 ','eat': 4, drink': 5}\n",
    "print( tokenizer.word_docs) #{'some': 2, 'thing': 2, 'to': 2, 'drink': 1,  'eat': 1}\n",
    "print( tokenizer.index_docs) #{1: 2, 2: 2, 3: 2, 4: 1, 5: 1}\n",
    "print(\"\\n\\n\")\n",
    "# num_words=多少会影响下面的结果，行数=num_words\n",
    "docs_index = tokenizer.texts_to_sequences(texts)\n",
    "print( max(docs_index) ) #得到词索引[[1, 2, 3, 4], [1, 2, 3, 5]]\n",
    "# print( tokenizer.texts_to_matrix(texts))  # 矩阵化=one_hot\n",
    "# [[ 0.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
    "#  [ 0.,  1.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "george\n"
     ]
    }
   ],
   "source": [
    "mydict = {'george':16,'amber':19}\n",
    "ss = list(mydict.keys())[list(mydict.values()).index(16)]\n",
    "print(ss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
