{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import scipy\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras_contrib.layers.normalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from data_loader import DataLoader\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pix2Pix():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 128\n",
    "        self.img_cols = 128\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        # Configure data loader\n",
    "        self.dataset_name = 'train'\n",
    "        dataset_name_t = self.dataset_name + \"/White\"\n",
    "        self.train_data_loader = DataLoader(dataset_name= dataset_name_t, img_res=(self.img_rows, self.img_cols))\n",
    "        dataset_name_t = self.dataset_name + \"/Real\"\n",
    "        self.label_data_loader = DataLoader(dataset_name= dataset_name_t, img_res=(self.img_rows, self.img_cols))\n",
    "        self.test_data_loader = DataLoader(dataset_name=\"test\", img_res=(self.img_rows, self.img_cols))\n",
    "        \n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        patch = int(self.img_rows / 2**4)\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "\n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.gf = 32\n",
    "        self.df = 32\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        #-------------------------\n",
    "        # Construct Computational\n",
    "        #   Graph of Generator\n",
    "        #-------------------------\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # Input images and their conditioning images\n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        img_B = Input(shape=self.img_shape)\n",
    "\n",
    "        # By conditioning on B generate a fake version of A\n",
    "        fake_A = self.generator(img_B)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # Discriminators determines validity of translated images / condition pairs\n",
    "        valid = self.discriminator([fake_A, img_B])\n",
    "\n",
    "        self.combined = Model(inputs=[img_A, img_B], outputs=[valid, fake_A])\n",
    "        self.combined.compile(loss=['mse', 'mae'], loss_weights=[1, 100], optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "        \"\"\"U-Net Generator\"\"\"\n",
    "\n",
    "        def conv2d(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Layers used during downsampling\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "            \"\"\"Layers used during upsampling\"\"\"\n",
    "            u = UpSampling2D(size=2)(layer_input)\n",
    "            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
    "            if dropout_rate:\n",
    "                u = Dropout(dropout_rate)(u)\n",
    "            u = BatchNormalization(momentum=0.8)(u)\n",
    "            u = Concatenate()([u, skip_input])\n",
    "            return u\n",
    "\n",
    "        # Image input\n",
    "        d0 = Input(shape=self.img_shape)\n",
    "\n",
    "        # Downsampling\n",
    "        d1 = conv2d(d0, self.gf, bn=False)\n",
    "        d2 = conv2d(d1, self.gf*2)\n",
    "        d3 = conv2d(d2, self.gf*4)\n",
    "        d4 = conv2d(d3, self.gf*8)\n",
    "        d5 = conv2d(d4, self.gf*8)\n",
    "        d6 = conv2d(d5, self.gf*8)\n",
    "        d7 = conv2d(d6, self.gf*8)\n",
    "\n",
    "        # Upsampling\n",
    "        u1 = deconv2d(d7, d6, self.gf*8)\n",
    "        u2 = deconv2d(u1, d5, self.gf*8)\n",
    "        u3 = deconv2d(u2, d4, self.gf*8)\n",
    "        u4 = deconv2d(u3, d3, self.gf*4)\n",
    "        u5 = deconv2d(u4, d2, self.gf*2)\n",
    "        u6 = deconv2d(u5, d1, self.gf)\n",
    "\n",
    "        u7 = UpSampling2D(size=2)(u6)\n",
    "        output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='sigmoid')(u7)\n",
    "\n",
    "        return Model(d0, output_img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        def d_layer(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        img_B = Input(shape=self.img_shape)\n",
    "\n",
    "        # Concatenate image and conditioning image by channels to produce input\n",
    "        combined_imgs = Concatenate(axis=-1)([img_A, img_B])\n",
    "\n",
    "        d1 = d_layer(combined_imgs, self.df, bn=False)\n",
    "        d2 = d_layer(d1, self.df*2)\n",
    "        d3 = d_layer(d2, self.df*4)\n",
    "        d4 = d_layer(d3, self.df*8)\n",
    "\n",
    "        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
    "\n",
    "        return Model([img_A, img_B], validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=1, sample_interval=50):\n",
    "        all_d_loss = np.zeros(epochs)\n",
    "        all_g_loss = np.zeros(epochs)\n",
    "        start_time = datetime.datetime.now()\n",
    "        \n",
    "        # Adversarial loss ground truths\n",
    "        valid = np.ones((batch_size,) + self.disc_patch)\n",
    "        fake = np.zeros((batch_size,) + self.disc_patch)\n",
    "        \n",
    "        #  Train Discriminator\n",
    "        for epoch in range(0, epochs):\n",
    "            narray_imgsB_t = self.train_data_loader.load_batch(batch_size)\n",
    "            narray_imgsB = list(narray_imgsB_t)\n",
    "            \n",
    "            for batch_i, imgs_A in enumerate(self.label_data_loader.load_batch(batch_size)):\n",
    "                imgs_B = narray_imgsB[batch_i]\n",
    "                \n",
    "                # Condition on B and generate a translated version\n",
    "                fake_A = self.generator.predict(imgs_B)\n",
    "                \n",
    "                # Train the discriminators (original images = real / generated = Fake)\n",
    "                d_loss_real = self.discriminator.train_on_batch([imgs_A, imgs_B], valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch([fake_A, imgs_B], fake)\n",
    "                \n",
    "                d_loss_real = self.discriminator.train_on_batch([imgs_A, imgs_B], valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch([fake_A, imgs_B], fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "                \n",
    "                # Train the generators\n",
    "                g_loss = self.combined.train_on_batch([imgs_A, imgs_B], [valid, imgs_A])\n",
    "                    \n",
    "                elapsed_time = str(datetime.datetime.now() - start_time)\n",
    "            all_d_loss[epoch] = d_loss[0]\n",
    "            all_g_loss[epoch] = g_loss[0]\n",
    "            print_out = (epoch, epochs, d_loss[0], 100*d_loss[1], g_loss[0],elapsed_time.split(\".\")[0])\n",
    "            print (\"[Epoch %d/%d]  [D loss: %f, acc: %3d%%] [G loss: %f] time: %s\" % print_out)\n",
    "        np.savetxt(\"all_d_loss.txt\", all_d_loss, delimiter=\",\")\n",
    "        np.savetxt(\"all_g_loss.txt\", all_g_loss, delimiter=\",\")\n",
    "\n",
    "                \n",
    "    def sample_images(self, epoch, batch_i):\n",
    "        os.makedirs('res_images/', exist_ok=True)\n",
    "\n",
    "        imgs_B = self.test_data_loader.load_data(batch_size=3, is_testing=True)\n",
    "        fake_A = self.generator.predict(imgs_B)\n",
    "\n",
    "        gen_imgs = np.concatenate([imgs_B, fake_A])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        ids = 0\n",
    "        for img in gen_imgs:\n",
    "            plt.imsave(\"res_images/test_res\" + str(ids) + \".jpg\", img)\n",
    "            ids += 1                  \n",
    "                \n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_5 (Model)                 (None, 128, 128, 3)  10468675    input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_4 (Model)                 (None, 8, 8, 1)      697569      model_5[1][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 11,166,244\n",
      "Trainable params: 10,464,259\n",
      "Non-trainable params: 701,985\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    gan = Pix2Pix()\n",
    "    gan.combined.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/20]  [D loss: 0.562546, acc:  57%] [G loss: 15793.648438] time: 0:00:09\n",
      "[Epoch 1/20]  [D loss: 0.136720, acc:  85%] [G loss: 15781.405273] time: 0:00:11\n",
      "[Epoch 2/20]  [D loss: 0.316281, acc:  66%] [G loss: 15754.381836] time: 0:00:14\n",
      "[Epoch 3/20]  [D loss: 0.358165, acc:  57%] [G loss: 15754.224609] time: 0:00:16\n",
      "[Epoch 4/20]  [D loss: 0.416254, acc:  63%] [G loss: 15754.259766] time: 0:00:18\n",
      "[Epoch 5/20]  [D loss: 0.322578, acc:  73%] [G loss: 15754.135742] time: 0:00:20\n",
      "[Epoch 6/20]  [D loss: 0.425538, acc:  66%] [G loss: 15753.929688] time: 0:00:22\n",
      "[Epoch 7/20]  [D loss: 0.732383, acc:  50%] [G loss: 15753.970703] time: 0:00:24\n",
      "[Epoch 8/20]  [D loss: 0.307459, acc:  67%] [G loss: 15753.879883] time: 0:00:26\n",
      "[Epoch 9/20]  [D loss: 0.180059, acc:  81%] [G loss: 15753.885742] time: 0:00:28\n",
      "[Epoch 10/20]  [D loss: 0.260417, acc:  71%] [G loss: 15753.885742] time: 0:00:30\n",
      "[Epoch 11/20]  [D loss: 0.198642, acc:  74%] [G loss: 15753.880859] time: 0:00:32\n",
      "[Epoch 12/20]  [D loss: 0.163093, acc:  80%] [G loss: 15753.865234] time: 0:00:34\n",
      "[Epoch 13/20]  [D loss: 0.187190, acc:  78%] [G loss: 15753.847656] time: 0:00:37\n",
      "[Epoch 14/20]  [D loss: 0.100556, acc:  90%] [G loss: 15753.854492] time: 0:00:39\n",
      "[Epoch 15/20]  [D loss: 0.087772, acc:  91%] [G loss: 15753.858398] time: 0:00:41\n",
      "[Epoch 16/20]  [D loss: 0.101681, acc:  91%] [G loss: 15753.859375] time: 0:00:43\n",
      "[Epoch 17/20]  [D loss: 0.141418, acc:  82%] [G loss: 15753.857422] time: 0:00:45\n",
      "[Epoch 18/20]  [D loss: 0.161060, acc:  85%] [G loss: 15753.835938] time: 0:00:47\n",
      "[Epoch 19/20]  [D loss: 0.113835, acc:  86%] [G loss: 15753.853516] time: 0:00:49\n"
     ]
    }
   ],
   "source": [
    "    gan.train(epochs= 20, batch_size= 1, sample_interval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     gan.sample_images(20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (10, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "    imgs_test = gan.test_data_loader.load_data(batch_size=10)\n",
    "    print(type(imgs_test) , imgs_test.shape)\n",
    "    fake_A = gan.generator.predict(imgs_test)\n",
    "\n",
    "    gen_imgs = np.concatenate([fake_A])\n",
    "#     gen_imgs = 0.5 * gen_imgs\n",
    "\n",
    "    ids = 0\n",
    "    for img in gen_imgs:\n",
    "        plt.imsave(\"res_images/test_res\" + str(ids) + \".jpg\", img)\n",
    "        ids += 1                  \n",
    "        plt.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw loss \n",
    "all_d_loss_txt = np.loadtxt(\"all_d_loss.txt\")\n",
    "all_g_loss_txt = np.loadtxt(\"all_g_loss.txt\")\n",
    "\n",
    "# print(all_d_loss_txt, all_d_loss_txt.shape, all_d_loss_txt.shape[0])\n",
    "# print(all_g_loss_txt, all_g_loss_txt.shape, all_g_loss_txt.shape[0])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "all_d_loss_x = np.linspace(0, 1, all_d_loss_txt.shape[0])\n",
    "all_g_loss_x = np.linspace(0, 1, all_g_loss_txt.shape[0])\n",
    "\n",
    "plt.plot(all_g_loss_x, all_g_loss_txt, '-r');  # dotted red, g_loss\n",
    "plt.plot(all_d_loss_x, all_d_loss_txt, '-g');  # dotted green, d_loss\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
