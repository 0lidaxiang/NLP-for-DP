{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import *\n",
    "from glob import glob\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras_contrib.layers.normalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pix2Pix():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 128\n",
    "        self.img_cols = 128\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "#         self.img_shape = (self.channels, self.img_rows, self.img_cols)\n",
    "\n",
    "        # Configure data loader\n",
    "        self.dataset_name = 'train'\n",
    "        \n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        patch = int(self.img_rows / 2**4)\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "\n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.gf = 64\n",
    "        self.df = 64\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        #-------------------------\n",
    "        # Construct Computational\n",
    "        #   Graph of Generator\n",
    "        #-------------------------\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        \n",
    "        # Input images and their conditioning images\n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        img_B = Input(shape=self.img_shape)\n",
    "\n",
    "        # By conditioning on B generate a fake version of A\n",
    "        fake_A = self.generator(img_B)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # Discriminators determines validity of translated images / condition pairs\n",
    "        valid = self.discriminator([fake_A, img_B])\n",
    "\n",
    "        self.combined = Model(inputs=[img_A, img_B], outputs=[valid, fake_A])\n",
    "        self.combined.compile(loss=['mse', 'mae'], loss_weights=[1, 100], optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "        \"\"\"U-Net Generator\"\"\"\n",
    "\n",
    "        def conv2d(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Layers used during downsampling\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "            \"\"\"Layers used during upsampling\"\"\"\n",
    "            u = UpSampling2D(size=2)(layer_input)\n",
    "            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
    "            if dropout_rate:\n",
    "                u = Dropout(dropout_rate)(u)\n",
    "            u = BatchNormalization(momentum=0.8)(u)\n",
    "            u = Concatenate()([u, skip_input])\n",
    "            return u\n",
    "\n",
    "        # Image input\n",
    "        d0 = Input(shape=self.img_shape)\n",
    "\n",
    "        # Downsampling\n",
    "        d1 = conv2d(d0, self.gf, bn=False)\n",
    "        d2 = conv2d(d1, self.gf*2)\n",
    "        d3 = conv2d(d2, self.gf*4)\n",
    "        d4 = conv2d(d3, self.gf*8)\n",
    "        d5 = conv2d(d4, self.gf*8)\n",
    "        d6 = conv2d(d5, self.gf*8)\n",
    "        d7 = conv2d(d6, self.gf*8)\n",
    "\n",
    "        # Upsampling\n",
    "        u1 = deconv2d(d7, d6, self.gf*8)\n",
    "        u2 = deconv2d(u1, d5, self.gf*8)\n",
    "        u3 = deconv2d(u2, d4, self.gf*8)\n",
    "        u4 = deconv2d(u3, d3, self.gf*4)\n",
    "        u5 = deconv2d(u4, d2, self.gf*2)\n",
    "        u6 = deconv2d(u5, d1, self.gf)\n",
    "\n",
    "        u7 = UpSampling2D(size=2)(u6)\n",
    "        output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='sigmoid')(u7)\n",
    "\n",
    "        return Model(d0, output_img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        def d_layer(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        img_B = Input(shape=self.img_shape)\n",
    "\n",
    "        # Concatenate image and conditioning image by channels to produce input\n",
    "        combined_imgs = Concatenate(axis=-1)([img_A, img_B])\n",
    "\n",
    "        d1 = d_layer(combined_imgs, self.df, bn=False)\n",
    "        d2 = d_layer(d1, self.df*2)\n",
    "        d3 = d_layer(d2, self.df*4)\n",
    "        d4 = d_layer(d3, self.df*8)\n",
    "\n",
    "        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
    "\n",
    "        return Model([img_A, img_B], validity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generator: \n",
      "discriminator: \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    gan = Pix2Pix()\n",
    "    print(\"generator: \")\n",
    "#     gan.generator.summary()\n",
    "    print(\"discriminator: \")\n",
    "#     gan.discriminator.summary()\n",
    "#     gan.combined.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def generator_training_Img(real_list_dir,white_list_dir,resize=None,batch_size=32):\n",
    "        batch_real_img=[]\n",
    "        batch_white_img=[]\n",
    "        for _ in range(batch_size):\n",
    "            random_img_index = np.random.randint(0, 254, size=1)[0]\n",
    "            real_img =  imread(real_list_dir[random_img_index] , mode='L')\n",
    "            white_img =  imread(white_list_dir[random_img_index] , mode='L')\n",
    "\n",
    "            if resize:\n",
    "                real_img = imresize(real_img,resize)\n",
    "                white_img = imresize(white_img,resize)\n",
    "            batch_real_img.append(real_img)\n",
    "            batch_white_img.append(white_img)\n",
    "        batch_real_img = np.array(batch_real_img)/127.5-1\n",
    "        batch_real_img = np.expand_dims(batch_real_img,axis=1)\n",
    "        batch_white_img = np.array(batch_white_img)/127.5-1\n",
    "        batch_white_img = np.expand_dims(batch_white_img,axis=3)\n",
    "        return batch_real_img,batch_white_img\n",
    "    \n",
    "    def generator_test_Img(white_list_dir,resize=None ):\n",
    "        batch_real_img=[]\n",
    "        batch_white_img=[]\n",
    "        for i in range(10):\n",
    "            white_img =  imread(white_list_dir[i] , mode='L')\n",
    "\n",
    "            if resize:\n",
    "                white_img = imresize(white_img,resize)\n",
    "            batch_white_img.append(white_img)\n",
    "        batch_white_img = np.array(batch_white_img)/127.5-1\n",
    "        batch_white_img = np.expand_dims(batch_white_img,axis=3)\n",
    "        return batch_white_img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    train_real_data_dir = r'./datasets/train/Real/*'\n",
    "    train_white_data_dir = r'./datasets/train/White/*'\n",
    "\n",
    "    real_list = glob(train_real_data_dir)\n",
    "    train_real_data_list = []\n",
    "    train_real_data_list.extend(real_list)\n",
    "\n",
    "    white_list = glob(train_white_data_dir)\n",
    "    train_white_data_list = []\n",
    "    train_white_data_list.extend(white_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  import sys\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/7000]  [D loss: 9.412760, acc:  17%] [G loss: 48.661789] time: 0:02:05\n"
     ]
    }
   ],
   "source": [
    "    epochs = 7000\n",
    "    batch_size_val = 32\n",
    "    all_d_loss = np.zeros(epochs)\n",
    "    all_g_loss = np.zeros(epochs)\n",
    "        \n",
    "    # Adversarial loss ground truths\n",
    "    valid = np.ones((batch_size_val, 8, 8,1))\n",
    "    fake  = np.zeros((batch_size_val, 8, 8, 1))\n",
    "\n",
    "    for epoch in range(0, epochs):\n",
    "            start_time = datetime.datetime.now()\n",
    "            \n",
    "            ori_img,white_img = generator_training_Img(real_list_dir=train_real_data_list,\n",
    "                                               white_list_dir=train_white_data_list,\n",
    "                                               resize=(128,128),\n",
    "                                               batch_size= batch_size_val)\n",
    "            imgs_A = ori_img \n",
    "            imgs_B = white_img \n",
    "            imgs_B = imgs_B.reshape((32,128,128,1))\n",
    "            imgs_A = imgs_A.reshape((32,128,128,1))\n",
    "            \n",
    "#             if epoch % 200 == 0 :\n",
    "#                 gan.combined.save('combined' + str(epoch) + '.h5') \n",
    "#                 gan.generator.save('generator' + str(epoch) + '.h5') \n",
    "#                 gan.discriminator.save('disc' + str(epoch) + '.h5') \n",
    "            \n",
    "            ###################################\n",
    "            #Training Discriminator Phase\n",
    "            ###################################\n",
    "            fake_A = gan.generator.predict(imgs_B)\n",
    "\n",
    "            d_loss_real = gan.discriminator.train_on_batch([imgs_A, imgs_B], valid)\n",
    "            d_loss_fake = gan.discriminator.train_on_batch([fake_A, imgs_B], fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "                    \n",
    "            for i in range(4):\n",
    "                g_loss = gan.combined.train_on_batch([imgs_A, imgs_B], [valid, imgs_A])\n",
    "            \n",
    "            all_d_loss[epoch] = d_loss[0]\n",
    "            all_g_loss[epoch] = g_loss[0]\n",
    "            \n",
    "            elapsed_time = str(datetime.datetime.now() - start_time)\n",
    "            print_out = (epoch, epochs, d_loss[0], 100*d_loss[1], g_loss[0],elapsed_time.split(\".\")[0])\n",
    "            print (\"[Epoch %d/%d]  [D loss: %f, acc: %3d%%] [G loss: %f] time: %s\" % print_out)\n",
    "            np.savetxt(\"all_d_loss.txt\", all_d_loss, delimiter=\",\")\n",
    "            np.savetxt(\"all_g_loss.txt\", all_g_loss, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    test_white_data_dir = r'./datasets/test/*'\n",
    "    test_white_list = glob(test_white_data_dir)\n",
    "    test_white_data_list = []\n",
    "    test_white_data_list.extend(test_white_list)\n",
    "    test_white_data_list = sorted(test_white_data_list)\n",
    "    \n",
    "    print(len(test_white_data_list), test_white_data_list)\n",
    "    test_white_data_list = generator_test_Img( white_list_dir=test_white_data_list, resize=(128,128))\n",
    "#     print(len(test_white_data_list), test_white_data_list)\n",
    "    \n",
    "    fake_A = gan.generator.predict(test_white_data_list)\n",
    "#     gen_imgs = fake_A\n",
    "    gen_imgs = np.concatenate([fake_A])\n",
    "    gen_imgs = 0.5 * gen_imgs\n",
    "    print(gen_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ids = 0\n",
    "    for img in gen_imgs:\n",
    "        img = img.reshape((128, 128))\n",
    "        plt.imsave(\"res_images/main_test_res_\" + str(ids) + \".jpg\", img, cmap=\"gray\")\n",
    "        ids += 1                  \n",
    "    plt.close()   \n",
    "    print(\"test_data generator predict over.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_csv(input_image,image_number=10,save_csv_name='predict.csv'):\n",
    "    save_image=np.zeros([int(input_image.size/image_number),image_number],dtype=np.float32)\n",
    "\n",
    "    for image_index in range(image_number):\n",
    "        save_image[:,image_index]=input_image[image_index,:,:].flatten()\n",
    "\n",
    "    base_word='id'\n",
    "    df = pd.DataFrame(save_image)\n",
    "    index_col=[]\n",
    "    for i in range(n):\n",
    "        col_word=base_word+str(i)\n",
    "        index_col.append(col_word)\n",
    "    df.index.name='index'\n",
    "    df.columns=index_col\n",
    "    df.to_csv(save_csv_name)\n",
    "    print(\"Okay! numpy_to_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_array = (image_array+1)/2                   \n",
    "n=10\n",
    "numpy_to_csv(input_image= gen_imgs,image_number=n,save_csv_name='Predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw loss \n",
    "all_d_loss_txt = np.loadtxt(\"all_d_loss.txt\")\n",
    "all_g_loss_txt = np.loadtxt(\"all_g_loss.txt\")\n",
    "\n",
    "# print( all_d_loss_txt.shape, all_d_loss_txt.shape[0])\n",
    "# print(all_g_loss_txt, all_g_loss_txt.shape, all_g_loss_txt.shape[0])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "all_d_loss_x = np.linspace(0, 1, all_d_loss_txt.shape[0])\n",
    "all_g_loss_x = np.linspace(0, 1, all_g_loss_txt.shape[0])\n",
    "\n",
    "plt.plot(all_g_loss_x, all_g_loss_txt, '-r');  # dotted red, g_loss\n",
    "# plt.plot(all_d_loss_x , all_d_loss_txt , '-g');  # dotted green, d_loss\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
