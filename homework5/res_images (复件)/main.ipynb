{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import *\n",
    "# from skimage.transform import resize as imresize\n",
    "# import imageio\n",
    "from glob import glob\n",
    "\n",
    "from __future__ import print_function, division\n",
    "from keras.datasets import mnist\n",
    "from keras_contrib.layers.normalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pix2Pix():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 128\n",
    "        self.img_cols = 128\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "#         self.img_shape = (self.channels, self.img_rows, self.img_cols)\n",
    "\n",
    "        # Configure data loader\n",
    "        self.dataset_name = 'train'\n",
    "        \n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        patch = int(self.img_rows / 2**4)\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "\n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.gf = 32\n",
    "        self.df = 4\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        #-------------------------\n",
    "        # Construct Computational\n",
    "        #   Graph of Generator\n",
    "        #-------------------------\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        \n",
    "        # Input images and their conditioning images\n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        img_B = Input(shape=self.img_shape)\n",
    "\n",
    "        # By conditioning on B generate a fake version of A\n",
    "        fake_A = self.generator(img_B)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # Discriminators determines validity of translated images / condition pairs\n",
    "        valid = self.discriminator([fake_A, img_B])\n",
    "\n",
    "        self.combined = Model(inputs=[img_A, img_B], outputs=[valid, fake_A])\n",
    "        self.combined.compile(loss=['mse', 'mae'], loss_weights=[1, 100], optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "        \"\"\"U-Net Generator\"\"\"\n",
    "\n",
    "        def conv2d(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Layers used during downsampling\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "            \"\"\"Layers used during upsampling\"\"\"\n",
    "            u = UpSampling2D(size=2)(layer_input)\n",
    "            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
    "            if dropout_rate:\n",
    "                u = Dropout(dropout_rate)(u)\n",
    "            u = BatchNormalization(momentum=0.8)(u)\n",
    "            u = Concatenate()([u, skip_input])\n",
    "            return u\n",
    "\n",
    "        # Image input\n",
    "        d0 = Input(shape=self.img_shape)\n",
    "\n",
    "        # Downsampling\n",
    "        d1 = conv2d(d0, self.gf, bn=False)\n",
    "        d2 = conv2d(d1, self.gf*2)\n",
    "        d3 = conv2d(d2, self.gf*4)\n",
    "        d4 = conv2d(d3, self.gf*8)\n",
    "        d5 = conv2d(d4, self.gf*8)\n",
    "        d6 = conv2d(d5, self.gf*8)\n",
    "        d7 = conv2d(d6, self.gf*8)\n",
    "\n",
    "        # Upsampling\n",
    "        u1 = deconv2d(d7, d6, self.gf*8)\n",
    "        u2 = deconv2d(u1, d5, self.gf*8)\n",
    "        u3 = deconv2d(u2, d4, self.gf*8)\n",
    "        u4 = deconv2d(u3, d3, self.gf*4)\n",
    "        u5 = deconv2d(u4, d2, self.gf*2)\n",
    "        u6 = deconv2d(u5, d1, self.gf)\n",
    "\n",
    "        u7 = UpSampling2D(size=2)(u6)\n",
    "        output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='sigmoid')(u7)\n",
    "\n",
    "        return Model(d0, output_img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        def d_layer(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        img_B = Input(shape=self.img_shape)\n",
    "\n",
    "        # Concatenate image and conditioning image by channels to produce input\n",
    "        combined_imgs = Concatenate(axis=-1)([img_A, img_B])\n",
    "\n",
    "        d1 = d_layer(combined_imgs, self.df, bn=False)\n",
    "        d2 = d_layer(d1, self.df*2)\n",
    "        d3 = d_layer(d2, self.df*4)\n",
    "        d4 = d_layer(d3, self.df*8)\n",
    "\n",
    "        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
    "\n",
    "        return Model([img_A, img_B], validity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 32)   544         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 64, 64, 32)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 64)   32832       leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 32, 32, 64)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 128)  131200      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 16, 16, 128)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 128)  512         leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 8, 256)    524544      batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 8, 8, 256)    0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 8, 256)    1024        leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 4, 4, 256)    1048832     batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 4, 4, 256)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 4, 4, 256)    1024        leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 2, 2, 256)    1048832     batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 2, 2, 256)    0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 2, 2, 256)    1024        leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 1, 1, 256)    1048832     batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 1, 1, 256)    0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1, 1, 256)    1024        leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 2, 2, 256)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 2, 2, 256)    1048832     up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 2, 2, 256)    1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2, 2, 512)    0           batch_normalization_10[0][0]     \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 4, 4, 512)    0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 4, 4, 256)    2097408     up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 4, 4, 256)    1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 4, 4, 512)    0           batch_normalization_11[0][0]     \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 8, 8, 512)    0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 256)    2097408     up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 256)    1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 8, 8, 512)    0           batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 16, 16, 512)  0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 128)  1048704     up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 16, 16, 256)  0           batch_normalization_13[0][0]     \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 32, 32, 256)  0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 64)   262208      up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 64)   256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 128)  0           batch_normalization_14[0][0]     \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 64, 64, 128)  0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 32)   65568       up_sampling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 64, 32)   128         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 64, 64, 64)   0           batch_normalization_15[0][0]     \n",
      "                                                                 leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 128, 128, 64) 0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 1)  1025        up_sampling2d_7[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 10,465,601\n",
      "Trainable params: 10,461,185\n",
      "Non-trainable params: 4,416\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 2)  0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 4)    132         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 64, 64, 4)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 8)    520         leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 32, 32, 8)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 8)    32          leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 16, 16)   2064        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 16, 16, 16)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 16)   64          leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 8, 8, 32)     8224        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 8, 8, 32)     0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 8, 32)     128         leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 8, 8, 1)      513         batch_normalization_3[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 23,242\n",
      "Trainable params: 11,565\n",
      "Non-trainable params: 11,677\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 128, 128, 1)  10465601    input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 8, 8, 1)      11677       model_2[1][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 10,477,278\n",
      "Trainable params: 10,461,185\n",
      "Non-trainable params: 16,093\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    gan = Pix2Pix()\n",
    "    gan.generator.summary()\n",
    "    gan.discriminator.summary()\n",
    "    gan.combined.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def generator_training_Img(real_list_dir,white_list_dir,resize=None,batch_size=32):\n",
    "        batch_real_img=[]\n",
    "        batch_white_img=[]\n",
    "        for _ in range(batch_size):\n",
    "            random_img_index = np.random.randint(0, 100, size=100)[0]\n",
    "            real_img =  imread(real_list_dir[random_img_index] , mode='L')\n",
    "            white_img =  imread(white_list_dir[random_img_index] , mode='L')\n",
    "\n",
    "            if resize:\n",
    "                real_img = imresize(real_img,resize)\n",
    "                white_img = imresize(white_img,resize)\n",
    "            batch_real_img.append(real_img)\n",
    "            batch_white_img.append(white_img)\n",
    "        batch_real_img = np.array(batch_real_img)/127.5-1\n",
    "        batch_real_img = np.expand_dims(batch_real_img,axis=1)\n",
    "        batch_white_img = np.array(batch_white_img)/127.5-1\n",
    "        batch_white_img = np.expand_dims(batch_white_img,axis=3)\n",
    "        return batch_real_img,batch_white_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1, 128, 128) (32, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  import sys\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "    train_real_data_dir = r'./datasets/train/Real/*'\n",
    "    train_white_data_dir = r'./datasets/train/White/*'\n",
    "\n",
    "    real_list = glob(train_real_data_dir)\n",
    "    train_real_data_list = []\n",
    "    train_real_data_list.extend(real_list)\n",
    "\n",
    "    white_list = glob(train_white_data_dir)\n",
    "    train_white_data_list = []\n",
    "    train_white_data_list.extend(white_list)\n",
    "    \n",
    "    ori_img,white_img = generator_training_Img(real_list_dir=train_real_data_list,\n",
    "                                               white_list_dir=train_white_data_list,\n",
    "                                               resize=(128,128),\n",
    "                                               batch_size=32)\n",
    "    print(ori_img.shape, white_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/30]  [D loss: 0.737710, acc:  42%] [G loss: 32.758915] time: 0:02:18\n",
      "[Epoch 1/30]  [D loss: 0.405639, acc:  52%] [G loss: 27.352535] time: 0:04:18\n",
      "[Epoch 2/30]  [D loss: 0.253291, acc:  68%] [G loss: 26.986748] time: 0:06:15\n",
      "[Epoch 3/30]  [D loss: 0.183284, acc:  76%] [G loss: 26.692223] time: 0:08:13\n",
      "[Epoch 4/30]  [D loss: 0.149620, acc:  81%] [G loss: 26.446163] time: 0:10:11\n",
      "[Epoch 5/30]  [D loss: 0.110501, acc:  87%] [G loss: 25.810738] time: 0:12:09\n",
      "[Epoch 6/30]  [D loss: 0.104208, acc:  86%] [G loss: 26.298527] time: 0:14:07\n",
      "[Epoch 7/30]  [D loss: 0.090743, acc:  87%] [G loss: 25.854471] time: 0:16:06\n",
      "[Epoch 8/30]  [D loss: 0.086429, acc:  89%] [G loss: 25.748848] time: 0:18:03\n",
      "[Epoch 9/30]  [D loss: 0.072981, acc:  93%] [G loss: 25.665401] time: 0:20:01\n",
      "[Epoch 10/30]  [D loss: 0.064462, acc:  96%] [G loss: 25.679544] time: 0:21:59\n",
      "[Epoch 11/30]  [D loss: 0.053797, acc:  97%] [G loss: 25.680796] time: 0:23:56\n",
      "[Epoch 12/30]  [D loss: 0.047715, acc:  98%] [G loss: 25.431028] time: 0:25:53\n",
      "[Epoch 13/30]  [D loss: 0.046431, acc:  97%] [G loss: 25.592201] time: 0:27:51\n",
      "[Epoch 14/30]  [D loss: 0.042454, acc:  98%] [G loss: 25.501545] time: 0:29:48\n",
      "[Epoch 15/30]  [D loss: 0.046909, acc:  97%] [G loss: 25.488413] time: 0:31:46\n",
      "[Epoch 16/30]  [D loss: 0.038471, acc:  98%] [G loss: 25.449211] time: 0:33:43\n",
      "[Epoch 17/30]  [D loss: 0.045768, acc:  98%] [G loss: 25.591713] time: 0:35:41\n",
      "[Epoch 18/30]  [D loss: 0.039624, acc:  98%] [G loss: 25.418541] time: 0:37:39\n",
      "[Epoch 19/30]  [D loss: 0.041682, acc:  98%] [G loss: 25.433889] time: 0:39:37\n",
      "[Epoch 20/30]  [D loss: 0.035058, acc:  98%] [G loss: 25.418381] time: 0:41:35\n",
      "[Epoch 21/30]  [D loss: 0.037290, acc:  98%] [G loss: 25.368738] time: 0:43:32\n",
      "[Epoch 22/30]  [D loss: 0.032379, acc:  99%] [G loss: 25.425175] time: 0:45:30\n",
      "[Epoch 23/30]  [D loss: 0.034944, acc:  99%] [G loss: 25.412416] time: 0:47:29\n",
      "[Epoch 24/30]  [D loss: 0.034524, acc:  99%] [G loss: 25.294289] time: 0:49:27\n",
      "[Epoch 25/30]  [D loss: 0.033165, acc:  99%] [G loss: 25.378567] time: 0:51:24\n",
      "[Epoch 26/30]  [D loss: 0.030451, acc: 100%] [G loss: 25.358809] time: 0:53:22\n",
      "[Epoch 27/30]  [D loss: 0.031653, acc:  99%] [G loss: 25.297092] time: 0:55:20\n",
      "[Epoch 28/30]  [D loss: 0.035317, acc:  98%] [G loss: 25.243328] time: 0:57:17\n",
      "[Epoch 29/30]  [D loss: 0.037722, acc:  99%] [G loss: 25.288994] time: 0:59:16\n"
     ]
    }
   ],
   "source": [
    "    epochs = 30\n",
    "    batch_size = 1\n",
    "    all_d_loss = np.zeros(epochs)\n",
    "    all_g_loss = np.zeros(epochs)\n",
    "    start_time = datetime.datetime.now()\n",
    "        \n",
    "    # Adversarial loss ground truths\n",
    "    valid = np.ones((batch_size,) + gan.disc_patch)\n",
    "    fake = np.zeros((batch_size,) + gan.disc_patch)\n",
    "        \n",
    "    #  Train Discriminator\n",
    "    \n",
    "    for epoch in range(0, epochs):\n",
    "            for batch_i in range(len(ori_img)):\n",
    "#                 print(batch_i)\n",
    "                imgs_A = ori_img[batch_i]\n",
    "                imgs_B = white_img[batch_i]\n",
    "                # Condition on B and generate a translated version\n",
    "                imgs_B = imgs_B.reshape((1,128,128,1))\n",
    "                imgs_A = imgs_A.reshape((1,128,128,1))\n",
    "                fake_A = gan.generator.predict(imgs_B)\n",
    "#                 plt.imshow(imgs_A[0].reshape((128,128)))\n",
    "#                 plt.imshow(imgs_B[0].reshape((128,128)))\n",
    "#                 plt.imshow(imgs_A[0])\n",
    "#                 break\n",
    "                \n",
    "                # Train the discriminators (original images = real / generated = Fake)\n",
    "                # imgs_B is white img\n",
    "                d_loss_real = gan.discriminator.train_on_batch([imgs_A, imgs_B], valid)\n",
    "                d_loss_fake = gan.discriminator.train_on_batch([fake_A, imgs_B], fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "                \n",
    "                # Train the generators\n",
    "                for i in range(8):\n",
    "                    g_loss = gan.combined.train_on_batch([imgs_A, imgs_B], [valid, imgs_A])\n",
    "                    #print_out = (epoch, epochs, d_loss[0], 100*d_loss[1], g_loss[0],elapsed_time.split(\".\")[0])\n",
    "                    #print (\"[Epoch %d/%d]  [D loss: %f, acc: %3d%%] [G loss: %f] time: %s\" % print_out)\n",
    "            \n",
    "            all_d_loss[epoch] = d_loss[0]\n",
    "            all_g_loss[epoch] = g_loss[0]\n",
    "            \n",
    "            elapsed_time = str(datetime.datetime.now() - start_time)\n",
    "            print_out = (epoch, epochs, d_loss[0], 100*d_loss[1], g_loss[0],elapsed_time.split(\".\")[0])\n",
    "            print (\"[Epoch %d/%d]  [D loss: %f, acc: %3d%%] [G loss: %f] time: %s\" % print_out)\n",
    "            np.savetxt(\"all_d_loss.txt\", all_d_loss, delimiter=\",\")\n",
    "            np.savetxt(\"all_g_loss.txt\", all_g_loss, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  import sys\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "    test_white_list = glob(train_white_data_dir)\n",
    "    test_white_data_list = []\n",
    "    test_white_data_list.extend(test_white_list)\n",
    "    \n",
    "    ori_img,test_white_data_list = generator_training_Img(real_list_dir=train_real_data_list,\n",
    "                                               white_list_dir=test_white_data_list,\n",
    "                                               resize=(128,128),\n",
    "                                               batch_size=10)\n",
    "    imgs_test = test_white_data_list\n",
    "#     imgs_test = imgs_test[:,:,:,:1]\n",
    "    fake_A = gan.generator.predict(test_white_data_list)\n",
    "    gen_imgs = np.concatenate([fake_A])\n",
    "#     gen_imgs = 0.5 * gen_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data generator predict over.\n"
     ]
    }
   ],
   "source": [
    "    ids = 0\n",
    "    for img in gen_imgs:\n",
    "        img = img.reshape((128, 128))\n",
    "        plt.imsave(\"res_images/main_test_res_\" + str(ids) + \".jpg\", img, cmap=\"gray\")\n",
    "        ids += 1                  \n",
    "    plt.close()   \n",
    "    print(\"test_data generator predict over.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw loss \n",
    "all_d_loss_txt = np.loadtxt(\"all_d_loss.txt\")\n",
    "all_g_loss_txt = np.loadtxt(\"all_g_loss.txt\")\n",
    "\n",
    "# print( all_d_loss_txt.shape, all_d_loss_txt.shape[0])\n",
    "# print(all_g_loss_txt, all_g_loss_txt.shape, all_g_loss_txt.shape[0])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "all_d_loss_x = np.linspace(0, 1, all_d_loss_txt.shape[0])\n",
    "all_g_loss_x = np.linspace(0, 1, all_g_loss_txt.shape[0])\n",
    "\n",
    "# plt.plot(all_g_loss_x, all_g_loss_txt, '-r');  # dotted red, g_loss\n",
    "plt.plot(all_d_loss_x , all_d_loss_txt , '-g');  # dotted green, d_loss\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     gan.sample_images(20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss = np.array([1,2,3])\n",
    "# ss[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
