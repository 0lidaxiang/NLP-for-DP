{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import *\n",
    "# from skimage.transform import resize as imresize\n",
    "# import imageio\n",
    "from glob import glob\n",
    "\n",
    "from __future__ import print_function, division\n",
    "from keras.datasets import mnist\n",
    "from keras_contrib.layers.normalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pix2Pix():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 128\n",
    "        self.img_cols = 128\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "#         self.img_shape = (self.channels, self.img_rows, self.img_cols)\n",
    "\n",
    "        # Configure data loader\n",
    "        self.dataset_name = 'train'\n",
    "        \n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        patch = int(self.img_rows / 2**4)\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "\n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.gf = 16\n",
    "        self.df = 4\n",
    "\n",
    "        optimizer = Adam(0.00005, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        #-------------------------\n",
    "        # Construct Computational\n",
    "        #   Graph of Generator\n",
    "        #-------------------------\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        \n",
    "        # Input images and their conditioning images\n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        img_B = Input(shape=self.img_shape)\n",
    "\n",
    "        # By conditioning on B generate a fake version of A\n",
    "        fake_A = self.generator(img_B)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # Discriminators determines validity of translated images / condition pairs\n",
    "        valid = self.discriminator([fake_A, img_B])\n",
    "\n",
    "        self.combined = Model(inputs=[img_A, img_B], outputs=[valid, fake_A])\n",
    "        self.combined.compile(loss=['mse', 'mae'], loss_weights=[1, 100], optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "        \"\"\"U-Net Generator\"\"\"\n",
    "\n",
    "        def conv2d(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Layers used during downsampling\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "#             if bn:\n",
    "#                 d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "            \"\"\"Layers used during upsampling\"\"\"\n",
    "            u = UpSampling2D(size=2)(layer_input)\n",
    "            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
    "            if dropout_rate:\n",
    "                u = Dropout(dropout_rate)(u)\n",
    "#             u = BatchNormalization(momentum=0.8)(u)\n",
    "            u = Concatenate()([u, skip_input])\n",
    "            return u\n",
    "\n",
    "        # Image input\n",
    "        d0 = Input(shape=self.img_shape)\n",
    "\n",
    "        # Downsampling\n",
    "        d1 = conv2d(d0, self.gf, bn=False)\n",
    "        d2 = conv2d(d1, self.gf*2)\n",
    "        d3 = conv2d(d2, self.gf*4)\n",
    "        d4 = conv2d(d3, self.gf*8)\n",
    "        d5 = conv2d(d4, self.gf*8)\n",
    "        d6 = conv2d(d5, self.gf*8)\n",
    "        d7 = conv2d(d6, self.gf*8)\n",
    "\n",
    "        # Upsampling\n",
    "        u1 = deconv2d(d7, d6, self.gf*8)\n",
    "        u2 = deconv2d(u1, d5, self.gf*8)\n",
    "        u3 = deconv2d(u2, d4, self.gf*8)\n",
    "        u4 = deconv2d(u3, d3, self.gf*4)\n",
    "        u5 = deconv2d(u4, d2, self.gf*2)\n",
    "        u6 = deconv2d(u5, d1, self.gf)\n",
    "\n",
    "        u7 = UpSampling2D(size=2)(u6)\n",
    "        output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='sigmoid')(u7)\n",
    "\n",
    "        return Model(d0, output_img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        def d_layer(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        img_B = Input(shape=self.img_shape)\n",
    "\n",
    "        # Concatenate image and conditioning image by channels to produce input\n",
    "        combined_imgs = Concatenate(axis=-1)([img_A, img_B])\n",
    "\n",
    "        d1 = d_layer(combined_imgs, self.df, bn=False)\n",
    "        d2 = d_layer(d1, self.df*2)\n",
    "        d3 = d_layer(d2, self.df*4)\n",
    "        d4 = d_layer(d3, self.df*8)\n",
    "\n",
    "        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
    "\n",
    "        return Model([img_A, img_B], validity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generator: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 16)   272         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 64, 64, 16)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 32)   8224        leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 32, 32, 32)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 64)   32832       leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 16, 16, 64)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 8, 128)    131200      leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 8, 8, 128)    0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 4, 4, 128)    262272      leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 4, 4, 128)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 2, 2, 128)    262272      leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 2, 2, 128)    0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 1, 1, 128)    262272      leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 1, 1, 128)    0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 2, 2, 128)    0           leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 2, 2, 128)    262272      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2, 2, 256)    0           conv2d_13[0][0]                  \n",
      "                                                                 leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 4, 4, 256)    0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 4, 4, 128)    524416      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 4, 4, 256)    0           conv2d_14[0][0]                  \n",
      "                                                                 leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 8, 8, 256)    0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 128)    524416      up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 8, 8, 256)    0           conv2d_15[0][0]                  \n",
      "                                                                 leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 16, 16, 256)  0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 64)   262208      up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 16, 16, 128)  0           conv2d_16[0][0]                  \n",
      "                                                                 leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 32, 32, 128)  0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 32)   65568       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 64)   0           conv2d_17[0][0]                  \n",
      "                                                                 leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 64, 64, 64)   0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 16)   16400       up_sampling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 64, 64, 32)   0           conv2d_18[0][0]                  \n",
      "                                                                 leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 128, 128, 32) 0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 1)  513         up_sampling2d_7[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 2,615,137\n",
      "Trainable params: 2,615,137\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "discriminator: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 2)  0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 4)    132         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 64, 64, 4)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 8)    520         leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 32, 32, 8)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 8)    32          leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 16, 16)   2064        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 16, 16, 16)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 16)   64          leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 8, 8, 32)     8224        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 8, 8, 32)     0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 8, 32)     128         leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 8, 8, 1)      513         batch_normalization_3[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 23,242\n",
      "Trainable params: 11,565\n",
      "Non-trainable params: 11,677\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 128, 128, 1)  2615137     input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 8, 8, 1)      11677       model_2[1][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,626,814\n",
      "Trainable params: 2,615,137\n",
      "Non-trainable params: 11,677\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    gan = Pix2Pix()\n",
    "    print(\"generator: \")\n",
    "    gan.generator.summary()\n",
    "    print(\"discriminator: \")\n",
    "    gan.discriminator.summary()\n",
    "    gan.combined.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def generator_training_Img(real_list_dir,white_list_dir,resize=None,batch_size=32):\n",
    "        batch_real_img=[]\n",
    "        batch_white_img=[]\n",
    "        for _ in range(batch_size):\n",
    "            random_img_index = np.random.randint(0, 304, size=1)[0]\n",
    "#             file_path = \"./datasets/train/Real/\" + str(random_img_index) + \".jpg\"\n",
    "#             if os.path.exists(file_path):\n",
    "            real_img =  imread(real_list_dir[random_img_index] , mode='L')\n",
    "            white_img =  imread(white_list_dir[random_img_index] , mode='L')\n",
    "\n",
    "            if resize:\n",
    "                real_img = imresize(real_img,resize)\n",
    "                white_img = imresize(white_img,resize)\n",
    "            batch_real_img.append(real_img)\n",
    "            batch_white_img.append(white_img)\n",
    "        batch_real_img = np.array(batch_real_img)/127.5-1\n",
    "        batch_real_img = np.expand_dims(batch_real_img,axis=1)\n",
    "        batch_white_img = np.array(batch_white_img)/127.5-1\n",
    "        batch_white_img = np.expand_dims(batch_white_img,axis=3)\n",
    "        return batch_real_img,batch_white_img\n",
    "    \n",
    "    def generator_test_Img(white_list_dir,resize=None ):\n",
    "        batch_real_img=[]\n",
    "        batch_white_img=[]\n",
    "        for i in range(10):\n",
    "#             random_img_index = np.random.randint(0, 10, size=1)[0]\n",
    "#             file_path = \"./datasets/train/Real/\" + str(random_img_index) + \".jpg\"\n",
    "#             if os.path.exists(file_path):\n",
    "            white_img =  imread(white_list_dir[i] , mode='L')\n",
    "\n",
    "            if resize:\n",
    "                white_img = imresize(white_img,resize)\n",
    "            batch_white_img.append(white_img)\n",
    "        batch_white_img = np.array(batch_white_img)/127.5-1\n",
    "        batch_white_img = np.expand_dims(batch_white_img,axis=3)\n",
    "        return batch_white_img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 1, 128, 128) (128, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "    train_real_data_dir = r'./datasets/train/Real/*'\n",
    "    train_white_data_dir = r'./datasets/train/White/*'\n",
    "\n",
    "    real_list = glob(train_real_data_dir)\n",
    "    train_real_data_list = []\n",
    "    train_real_data_list.extend(real_list)\n",
    "\n",
    "    white_list = glob(train_white_data_dir)\n",
    "    train_white_data_list = []\n",
    "    train_white_data_list.extend(white_list)\n",
    "    \n",
    "    ori_img,white_img = generator_training_Img(real_list_dir=train_real_data_list,\n",
    "                                               white_list_dir=train_white_data_list,\n",
    "                                               resize=(128,128),\n",
    "                                               batch_size=128)\n",
    "    print(ori_img.shape, white_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "    epochs = 100\n",
    "    batch_size = 1\n",
    "    all_d_loss = np.zeros(epochs)\n",
    "    all_g_loss = np.zeros(epochs)\n",
    "    start_time = datetime.datetime.now()\n",
    "        \n",
    "    # Adversarial loss ground truths\n",
    "    valid = np.ones((batch_size,) + gan.disc_patch)\n",
    "    fake = np.zeros((batch_size,) + gan.disc_patch)\n",
    "        \n",
    "    #  Train Discriminator\n",
    "    \n",
    "    for epoch in range(0, epochs):\n",
    "            for batch_i in range(len(ori_img)):\n",
    "                imgs_A = ori_img[batch_i]\n",
    "                imgs_B = white_img[batch_i]\n",
    "                # Condition on B and generate a translated version\n",
    "                imgs_B = imgs_B.reshape((1,128,128,1))\n",
    "                imgs_A = imgs_A.reshape((1,128,128,1))\n",
    "                fake_A = gan.generator.predict(imgs_B)\n",
    "#                 plt.imshow(imgs_A[0].reshape((128,128)))\n",
    "#                 plt.imshow(imgs_B[0].reshape((128,128)))\n",
    "#                 plt.imshow(imgs_A[0])\n",
    "#                 break\n",
    "                \n",
    "                # Train the discriminators (original images = real / generated = Fake)\n",
    "                # imgs_B is white img\n",
    "                d_loss_real = gan.discriminator.train_on_batch([imgs_A, imgs_B], valid)\n",
    "                d_loss_fake = gan.discriminator.train_on_batch([fake_A, imgs_B], fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "                \n",
    "                # Train the generators\n",
    "                for i in range(4):\n",
    "                    g_loss = gan.combined.train_on_batch([imgs_A, imgs_B], [valid, imgs_A])\n",
    "                    #print_out = (epoch, epochs, d_loss[0], 100*d_loss[1], g_loss[0],elapsed_time.split(\".\")[0])\n",
    "                    #print (\"[Epoch %d/%d]  [D loss: %f, acc: %3d%%] [G loss: %f] time: %s\" % print_out)\n",
    "            \n",
    "            all_d_loss[epoch] = d_loss[0]\n",
    "            all_g_loss[epoch] = g_loss[0]\n",
    "            \n",
    "            elapsed_time = str(datetime.datetime.now() - start_time)\n",
    "            print_out = (epoch, epochs, d_loss[0], 100*d_loss[1], g_loss[0],elapsed_time.split(\".\")[0])\n",
    "            print (\"[Epoch %d/%d]  [D loss: %f, acc: %3d%%] [G loss: %f] time: %s\" % print_out)\n",
    "            np.savetxt(\"all_d_loss.txt\", all_d_loss, delimiter=\",\")\n",
    "            np.savetxt(\"all_g_loss.txt\", all_g_loss, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    test_white_data_dir = r'./datasets/test/*'\n",
    "    test_white_list = glob(test_white_data_dir)\n",
    "    test_white_data_list = []\n",
    "    test_white_data_list.extend(test_white_list)\n",
    "    print(len(test_white_data_list), test_white_data_list)\n",
    "    test_white_data_list = generator_test_Img( white_list_dir=test_white_data_list, resize=(128,128))\n",
    "#     imgs_test = test_white_data_list\n",
    "#     print(imgs_test.shape)\n",
    "#     imgs_test = imgs_test[:,:,:,:1]\n",
    "    fake_A = gan.generator.predict(test_white_data_list)\n",
    "    gen_imgs = np.concatenate([fake_A])\n",
    "#     gen_imgs = 0.5 * gen_imgs\n",
    "    print(gen_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ids = 0\n",
    "    for img in gen_imgs:\n",
    "        img = img.reshape((128, 128))\n",
    "        plt.imsave(\"res_images/main_test_res_\" + str(ids) + \".jpg\", img, cmap=\"gray\")\n",
    "        ids += 1                  \n",
    "    plt.close()   \n",
    "    print(\"test_data generator predict over.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw loss \n",
    "all_d_loss_txt = np.loadtxt(\"all_d_loss.txt\")\n",
    "all_g_loss_txt = np.loadtxt(\"all_g_loss.txt\")\n",
    "\n",
    "# print( all_d_loss_txt.shape, all_d_loss_txt.shape[0])\n",
    "# print(all_g_loss_txt, all_g_loss_txt.shape, all_g_loss_txt.shape[0])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "all_d_loss_x = np.linspace(0, 1, all_d_loss_txt.shape[0])\n",
    "all_g_loss_x = np.linspace(0, 1, all_g_loss_txt.shape[0])\n",
    "\n",
    "# plt.plot(all_g_loss_x, all_g_loss_txt, '-r');  # dotted red, g_loss\n",
    "plt.plot(all_d_loss_x , all_d_loss_txt , '-g');  # dotted green, d_loss\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_csv(input_image,image_number=10,save_csv_name='predict.csv'):\n",
    "    save_image=np.zeros([int(input_image.size/image_number),image_number],dtype=np.float32)\n",
    "\n",
    "    for image_index in range(image_number):\n",
    "        save_image[:,image_index]=input_image[image_index,:,:].flatten()\n",
    "\n",
    "    base_word='id'\n",
    "    df = pd.DataFrame(save_image)\n",
    "    index_col=[]\n",
    "    for i in range(n):\n",
    "        col_word=base_word+str(i)\n",
    "        index_col.append(col_word)\n",
    "    df.index.name='index'\n",
    "    df.columns=index_col\n",
    "    df.to_csv(save_csv_name)\n",
    "    print(\"Okay! numpy_to_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_array = (image_array+1)/2                   \n",
    "n=10\n",
    "numpy_to_csv(input_image= gen_imgs,image_number=n,save_csv_name='Predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss = np.array([1,2,3])\n",
    "# ss[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
