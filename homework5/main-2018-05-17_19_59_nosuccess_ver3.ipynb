{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import *\n",
    "# from skimage.transform import resize as imresize\n",
    "# import imageio\n",
    "from glob import glob\n",
    "\n",
    "from __future__ import print_function, division\n",
    "from keras.datasets import mnist\n",
    "from keras_contrib.layers.normalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pix2Pix():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 128\n",
    "        self.img_cols = 128\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "#         self.img_shape = (self.channels, self.img_rows, self.img_cols)\n",
    "\n",
    "        # Configure data loader\n",
    "        self.dataset_name = 'train'\n",
    "        \n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        patch = int(self.img_rows / 2**4)\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "\n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.gf = 32\n",
    "        self.df = 2\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        #-------------------------\n",
    "        # Construct Computational\n",
    "        #   Graph of Generator\n",
    "        #-------------------------\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        \n",
    "        # Input images and their conditioning images\n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        img_B = Input(shape=self.img_shape)\n",
    "\n",
    "        # By conditioning on B generate a fake version of A\n",
    "        fake_A = self.generator(img_B)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # Discriminators determines validity of translated images / condition pairs\n",
    "        valid = self.discriminator([fake_A, img_B])\n",
    "\n",
    "        self.combined = Model(inputs=[img_A, img_B], outputs=[valid, fake_A])\n",
    "        self.combined.compile(loss=['mse', 'mae'], loss_weights=[1, 100], optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "        \"\"\"U-Net Generator\"\"\"\n",
    "\n",
    "        def conv2d(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Layers used during downsampling\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "            \"\"\"Layers used during upsampling\"\"\"\n",
    "            u = UpSampling2D(size=2)(layer_input)\n",
    "            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
    "            if dropout_rate:\n",
    "                u = Dropout(dropout_rate)(u)\n",
    "            u = BatchNormalization(momentum=0.8)(u)\n",
    "            u = Concatenate()([u, skip_input])\n",
    "            return u\n",
    "\n",
    "        # Image input\n",
    "        d0 = Input(shape=self.img_shape)\n",
    "\n",
    "        # Downsampling\n",
    "        d1 = conv2d(d0, self.gf, bn=False)\n",
    "        d2 = conv2d(d1, self.gf*2)\n",
    "        d3 = conv2d(d2, self.gf*4)\n",
    "        d4 = conv2d(d3, self.gf*8)\n",
    "        d5 = conv2d(d4, self.gf*8)\n",
    "        d6 = conv2d(d5, self.gf*8)\n",
    "        d7 = conv2d(d6, self.gf*8)\n",
    "\n",
    "        # Upsampling\n",
    "        u1 = deconv2d(d7, d6, self.gf*8)\n",
    "        u2 = deconv2d(u1, d5, self.gf*8)\n",
    "        u3 = deconv2d(u2, d4, self.gf*8)\n",
    "        u4 = deconv2d(u3, d3, self.gf*4)\n",
    "        u5 = deconv2d(u4, d2, self.gf*2)\n",
    "        u6 = deconv2d(u5, d1, self.gf)\n",
    "\n",
    "        u7 = UpSampling2D(size=2)(u6)\n",
    "        output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='sigmoid')(u7)\n",
    "\n",
    "        return Model(d0, output_img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        def d_layer(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        img_A = Input(shape=self.img_shape)\n",
    "        img_B = Input(shape=self.img_shape)\n",
    "\n",
    "        # Concatenate image and conditioning image by channels to produce input\n",
    "        combined_imgs = Concatenate(axis=-1)([img_A, img_B])\n",
    "\n",
    "        d1 = d_layer(combined_imgs, self.df, bn=False)\n",
    "        d2 = d_layer(d1, self.df*2)\n",
    "        d3 = d_layer(d2, self.df*4)\n",
    "        d4 = d_layer(d3, self.df*8)\n",
    "\n",
    "        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
    "\n",
    "        return Model([img_A, img_B], validity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 32)   544         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 64, 64, 32)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 64)   32832       leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 32, 32, 64)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 128)  131200      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 16, 16, 128)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 128)  512         leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 8, 256)    524544      batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 8, 8, 256)    0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 8, 256)    1024        leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 4, 4, 256)    1048832     batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 4, 4, 256)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 4, 4, 256)    1024        leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 2, 2, 256)    1048832     batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 2, 2, 256)    0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 2, 2, 256)    1024        leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 1, 1, 256)    1048832     batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 1, 1, 256)    0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1, 1, 256)    1024        leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 2, 2, 256)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 2, 2, 256)    1048832     up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 2, 2, 256)    1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2, 2, 512)    0           batch_normalization_10[0][0]     \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 4, 4, 512)    0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 4, 4, 256)    2097408     up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 4, 4, 256)    1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 4, 4, 512)    0           batch_normalization_11[0][0]     \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 8, 8, 512)    0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 256)    2097408     up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 256)    1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 8, 8, 512)    0           batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 16, 16, 512)  0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 128)  1048704     up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 16, 16, 256)  0           batch_normalization_13[0][0]     \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 32, 32, 256)  0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 64)   262208      up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 64)   256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 128)  0           batch_normalization_14[0][0]     \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 64, 64, 128)  0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 32)   65568       up_sampling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 64, 32)   128         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 64, 64, 64)   0           batch_normalization_15[0][0]     \n",
      "                                                                 leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 128, 128, 64) 0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 1)  1025        up_sampling2d_7[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 10,465,601\n",
      "Trainable params: 10,461,185\n",
      "Non-trainable params: 4,416\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 2)  0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 2)    66          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 64, 64, 2)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 4)    132         leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 32, 32, 4)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 4)    16          leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 16, 8)    520         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 16, 16, 8)    0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 8)    32          leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 8, 8, 16)     2064        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 8, 8, 16)     0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 8, 16)     64          leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 8, 8, 1)      257         batch_normalization_3[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 6,246\n",
      "Trainable params: 3,095\n",
      "Non-trainable params: 3,151\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 128, 128, 1)  10465601    input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 8, 8, 1)      3151        model_2[1][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 10,468,752\n",
      "Trainable params: 10,461,185\n",
      "Non-trainable params: 7,567\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    gan = Pix2Pix()\n",
    "    print(\"generator: \")\n",
    "    gan.generator.summary()\n",
    "    print(\"discriminator: \")\n",
    "    gan.discriminator.summary()\n",
    "    gan.combined.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def generator_training_Img(real_list_dir,white_list_dir,resize=None,batch_size=32):\n",
    "        batch_real_img=[]\n",
    "        batch_white_img=[]\n",
    "        for _ in range(batch_size):\n",
    "            random_img_index = np.random.randint(0, 100, size=100)[0]\n",
    "            real_img =  imread(real_list_dir[random_img_index] , mode='L')\n",
    "            white_img =  imread(white_list_dir[random_img_index] , mode='L')\n",
    "\n",
    "            if resize:\n",
    "                real_img = imresize(real_img,resize)\n",
    "                white_img = imresize(white_img,resize)\n",
    "            batch_real_img.append(real_img)\n",
    "            batch_white_img.append(white_img)\n",
    "        batch_real_img = np.array(batch_real_img)/127.5-1\n",
    "        batch_real_img = np.expand_dims(batch_real_img,axis=1)\n",
    "        batch_white_img = np.array(batch_white_img)/127.5-1\n",
    "        batch_white_img = np.expand_dims(batch_white_img,axis=3)\n",
    "        return batch_real_img,batch_white_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1, 128, 128) (32, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  import sys\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "    train_real_data_dir = r'./datasets/train/Real/*'\n",
    "    train_white_data_dir = r'./datasets/train/White/*'\n",
    "\n",
    "    real_list = glob(train_real_data_dir)\n",
    "    train_real_data_list = []\n",
    "    train_real_data_list.extend(real_list)\n",
    "\n",
    "    white_list = glob(train_white_data_dir)\n",
    "    train_white_data_list = []\n",
    "    train_white_data_list.extend(white_list)\n",
    "    \n",
    "    ori_img,white_img = generator_training_Img(real_list_dir=train_real_data_list,\n",
    "                                               white_list_dir=train_white_data_list,\n",
    "                                               resize=(128,128),\n",
    "                                               batch_size=32)\n",
    "    print(ori_img.shape, white_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/30]  [D loss: 0.972732, acc:  34%] [G loss: 15.173559] time: 0:01:57\n",
      "[Epoch 1/30]  [D loss: 0.605188, acc:  42%] [G loss: 12.198547] time: 0:03:54\n",
      "[Epoch 2/30]  [D loss: 0.441972, acc:  49%] [G loss: 11.307969] time: 0:05:56\n",
      "[Epoch 3/30]  [D loss: 0.388896, acc:  47%] [G loss: 10.623497] time: 0:07:55\n",
      "[Epoch 4/30]  [D loss: 0.325548, acc:  50%] [G loss: 10.216278] time: 0:09:58\n",
      "[Epoch 5/30]  [D loss: 0.282853, acc:  54%] [G loss: 9.919909] time: 0:12:11\n",
      "[Epoch 6/30]  [D loss: 0.279602, acc:  53%] [G loss: 9.788112] time: 0:14:33\n",
      "[Epoch 7/30]  [D loss: 0.289315, acc:  53%] [G loss: 9.668055] time: 0:16:48\n",
      "[Epoch 8/30]  [D loss: 0.265346, acc:  57%] [G loss: 9.552207] time: 0:18:53\n",
      "[Epoch 9/30]  [D loss: 0.277461, acc:  53%] [G loss: 9.560118] time: 0:21:02\n",
      "[Epoch 10/30]  [D loss: 0.263117, acc:  53%] [G loss: 9.331892] time: 0:23:20\n",
      "[Epoch 11/30]  [D loss: 0.279198, acc:  54%] [G loss: 9.331931] time: 0:25:28\n",
      "[Epoch 12/30]  [D loss: 0.290307, acc:  50%] [G loss: 9.379600] time: 0:27:26\n",
      "[Epoch 13/30]  [D loss: 0.274370, acc:  51%] [G loss: 9.165476] time: 0:29:26\n",
      "[Epoch 14/30]  [D loss: 0.257298, acc:  57%] [G loss: 9.048088] time: 0:31:25\n",
      "[Epoch 15/30]  [D loss: 0.287682, acc:  51%] [G loss: 9.085648] time: 0:33:23\n",
      "[Epoch 16/30]  [D loss: 0.280361, acc:  53%] [G loss: 9.194337] time: 0:35:22\n",
      "[Epoch 17/30]  [D loss: 0.246566, acc:  57%] [G loss: 8.958144] time: 0:37:21\n",
      "[Epoch 18/30]  [D loss: 0.266970, acc:  52%] [G loss: 8.972156] time: 0:39:19\n",
      "[Epoch 19/30]  [D loss: 0.242880, acc:  60%] [G loss: 8.918042] time: 0:41:18\n",
      "[Epoch 20/30]  [D loss: 0.238976, acc:  60%] [G loss: 8.914164] time: 0:43:17\n",
      "[Epoch 21/30]  [D loss: 0.244762, acc:  58%] [G loss: 8.927805] time: 0:45:15\n",
      "[Epoch 22/30]  [D loss: 0.223750, acc:  61%] [G loss: 8.856473] time: 0:47:13\n",
      "[Epoch 23/30]  [D loss: 0.230809, acc:  60%] [G loss: 8.884253] time: 0:49:12\n",
      "[Epoch 24/30]  [D loss: 0.229376, acc:  58%] [G loss: 8.796178] time: 0:51:10\n",
      "[Epoch 25/30]  [D loss: 0.220285, acc:  62%] [G loss: 9.007607] time: 0:53:08\n",
      "[Epoch 26/30]  [D loss: 0.221937, acc:  61%] [G loss: 8.820797] time: 0:55:06\n",
      "[Epoch 27/30]  [D loss: 0.213605, acc:  63%] [G loss: 8.792000] time: 0:57:05\n",
      "[Epoch 28/30]  [D loss: 0.201298, acc:  68%] [G loss: 9.014394] time: 0:59:03\n",
      "[Epoch 29/30]  [D loss: 0.208040, acc:  67%] [G loss: 9.027258] time: 1:01:01\n"
     ]
    }
   ],
   "source": [
    "    epochs = 30\n",
    "    batch_size = 1\n",
    "    all_d_loss = np.zeros(epochs)\n",
    "    all_g_loss = np.zeros(epochs)\n",
    "    start_time = datetime.datetime.now()\n",
    "        \n",
    "    # Adversarial loss ground truths\n",
    "    valid = np.ones((batch_size,) + gan.disc_patch)\n",
    "    fake = np.zeros((batch_size,) + gan.disc_patch)\n",
    "        \n",
    "    #  Train Discriminator\n",
    "    \n",
    "    for epoch in range(0, epochs):\n",
    "            for batch_i in range(len(ori_img)):\n",
    "#                 print(batch_i)\n",
    "                imgs_A = ori_img[batch_i]\n",
    "                imgs_B = white_img[batch_i]\n",
    "                # Condition on B and generate a translated version\n",
    "                imgs_B = imgs_B.reshape((1,128,128,1))\n",
    "                imgs_A = imgs_A.reshape((1,128,128,1))\n",
    "                fake_A = gan.generator.predict(imgs_B)\n",
    "#                 plt.imshow(imgs_A[0].reshape((128,128)))\n",
    "#                 plt.imshow(imgs_B[0].reshape((128,128)))\n",
    "#                 plt.imshow(imgs_A[0])\n",
    "#                 break\n",
    "                \n",
    "                # Train the discriminators (original images = real / generated = Fake)\n",
    "                # imgs_B is white img\n",
    "                d_loss_real = gan.discriminator.train_on_batch([imgs_A, imgs_B], valid)\n",
    "                d_loss_fake = gan.discriminator.train_on_batch([fake_A, imgs_B], fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "                \n",
    "                # Train the generators\n",
    "                for i in range(4):\n",
    "                    g_loss = gan.combined.train_on_batch([imgs_A, imgs_B], [valid, imgs_A])\n",
    "                    #print_out = (epoch, epochs, d_loss[0], 100*d_loss[1], g_loss[0],elapsed_time.split(\".\")[0])\n",
    "                    #print (\"[Epoch %d/%d]  [D loss: %f, acc: %3d%%] [G loss: %f] time: %s\" % print_out)\n",
    "            \n",
    "            all_d_loss[epoch] = d_loss[0]\n",
    "            all_g_loss[epoch] = g_loss[0]\n",
    "            \n",
    "            elapsed_time = str(datetime.datetime.now() - start_time)\n",
    "            print_out = (epoch, epochs, d_loss[0], 100*d_loss[1], g_loss[0],elapsed_time.split(\".\")[0])\n",
    "            print (\"[Epoch %d/%d]  [D loss: %f, acc: %3d%%] [G loss: %f] time: %s\" % print_out)\n",
    "            np.savetxt(\"all_d_loss.txt\", all_d_loss, delimiter=\",\")\n",
    "            np.savetxt(\"all_g_loss.txt\", all_g_loss, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  import sys\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "    test_white_list = glob(train_white_data_dir)\n",
    "    test_white_data_list = []\n",
    "    test_white_data_list.extend(test_white_list)\n",
    "    \n",
    "    ori_img,test_white_data_list = generator_training_Img(real_list_dir=train_real_data_list,\n",
    "                                               white_list_dir=test_white_data_list,\n",
    "                                               resize=(128,128),\n",
    "                                               batch_size=10)\n",
    "    imgs_test = test_white_data_list\n",
    "#     imgs_test = imgs_test[:,:,:,:1]\n",
    "    fake_A = gan.generator.predict(test_white_data_list)\n",
    "    gen_imgs = np.concatenate([fake_A])\n",
    "#     gen_imgs = 0.5 * gen_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data generator predict over.\n"
     ]
    }
   ],
   "source": [
    "    ids = 0\n",
    "    for img in gen_imgs:\n",
    "        img = img.reshape((128, 128))\n",
    "        plt.imsave(\"res_images/main_test_res_\" + str(ids) + \".jpg\", img, cmap=\"gray\")\n",
    "        ids += 1                  \n",
    "    plt.close()   \n",
    "    print(\"test_data generator predict over.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw loss \n",
    "all_d_loss_txt = np.loadtxt(\"all_d_loss.txt\")\n",
    "all_g_loss_txt = np.loadtxt(\"all_g_loss.txt\")\n",
    "\n",
    "# print( all_d_loss_txt.shape, all_d_loss_txt.shape[0])\n",
    "# print(all_g_loss_txt, all_g_loss_txt.shape, all_g_loss_txt.shape[0])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "all_d_loss_x = np.linspace(0, 1, all_d_loss_txt.shape[0])\n",
    "all_g_loss_x = np.linspace(0, 1, all_g_loss_txt.shape[0])\n",
    "\n",
    "# plt.plot(all_g_loss_x, all_g_loss_txt, '-r');  # dotted red, g_loss\n",
    "plt.plot(all_d_loss_x , all_d_loss_txt , '-g');  # dotted green, d_loss\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     gan.sample_images(20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss = np.array([1,2,3])\n",
    "# ss[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
